\documentclass[12pt]{article} 

\usepackage{geometry}
\geometry{a4paper} 

\usepackage{graphicx} 
\usepackage{enumitem}
\usepackage{booktabs}

\usepackage{float} 
\usepackage{wrapfig} 

\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{dsfont}

\usepackage{xcolor}
\usepackage{listings}
\usepackage{caption}
\DeclareCaptionFont{white}{\color{white}}
\DeclareCaptionFormat{listing}{%
  \parbox{\textwidth}{\colorbox{gray}{\parbox{\textwidth}{#1#2#3}}\vskip-2pt}}
\captionsetup[lstlisting]{format=listing,labelfont=white,textfont=white}
\lstset{frame=lrb,xleftmargin=\fboxsep,xrightmargin=-\fboxsep}

\linespread{1.2} 
\setlength{\parskip}{\baselineskip} % vertical spaces
\setlength\parindent{0pt} % remove all indentation from paragraphs


\usepackage{ntheorem}
\usepackage{mdframed}

\theoremstyle{nonumberbreak}
\theoremheaderfont{\bfseries}
\newmdtheoremenv[%
linecolor=gray,leftmargin=10,%
rightmargin=10,
backgroundcolor=gray!20,%
innertopmargin=0pt,%
ntheorem]{theorem}{}




\begin{document}

\title{\textbf{Geometric and Exponential Distributions}}
\author{Hyunwoo Gu}
\date{}

\maketitle

%----------------------------------------------------------------------------------------
%	Appendix
%----------------------------------------------------------------------------------------
\section*{Karlin: Renewal processes}
\setcounter{section}{0}


\section{Review: Basics \& Renewal Processes}



Let us consider \textbf{Poisson process} as an example of continous time Markov chains,

$$
\phi_t (w) = \mathbb{E} \{ e^{iwX(t)} \} = \sum_{n=0}^\infty \frac{e^{-\lambda t} (\lambda t)^n e^{iwn}}{n!} = exp[\lambda t (e^{iw} -1)]
$$

Thus 

$$
\mathbb{E} (X(t)) = \lambda t \ \ \mathrm{Var}(X(t)) = \lambda t
$$


\section{Poisson Processes: Continuous Time Markov Chains}


\subsection{Postulates for the Poisson process}


First, 

Notice that the right-hand side is independent of $x$. 

$$
\begin{aligned}
P\{ X(t+h) - X(t) = 1 | X(t) = x \} &= \lambda h + o(h), h \to 0_+, (x=0,1,2,\cdots) \\[10pt]
\Leftrightarrow \mathrm{lim}_{h \to 0+} \frac{P\{ X(t+h) - X(t) = 1 | X(t) = x \}}{h} = \lambda
\end{aligned}
$$



Second


$$
P\{ X(t+h) - X(t) = 0 | X(t) = x \} = 1 - \lambda h + o(h), h \to 0_+
$$


Third,

$$
X(0) = 0 
$$


\subsection{Pure birth process}

A natural generalization of the Poisson process is to permit the chance of
an event occurring at a given instant of time to depend upon the number of events which have already occurred. For example, \textbf{the probability of a birth at a given instant is proportional to the population size at that time}, which is known as the \textbf{Yule process}.




The characteristic function of $S_n$ is given by

$$
\phi_n(w) = \mathbb{E}(exp(iwS_n)) = \prod_{k=0}^{n-1} \mathbb{E}(exp(iw T_k)) = \prod_{k=0}^{n-1} \frac{\lambda_k}{\lambda_k - iw}
$$


\subsection{Yule process}



$$
\begin{aligned}
f_N(s) &= [f(s)]^N \\[8pt]
&= \left[ \frac{se^{-\beta t}}{1 - (1-e^{-\beta t})s} \right]^N \\[8pt]
&= (s e^{-\beta t})^N \sum_{m=0}^infty 
\end{aligned}
$$




\begin{theorem}
\textbf{Theorem 2.1}. The waiting times $T_k$ are independent and indentically distributed following an exponential distribution with parameter $\lambda$. 
\end{theorem}



\begin{theorem}
\textbf{Theorem 2.2}. Let $F(x)$ a distribution such that $F(0) = 0$ and $F(x) < 1$ for some $x >0 $, then $F(x)$ is an exponential distribution iff

$$
F(x+y) - F(y) = F(x)[1-F(y)], \forall x,y \ge 0
$$
\end{theorem}

\textbf{Proof}. ($\Rightarrow$) 




\begin{theorem}
\textbf{Theorem 2.3}. Let $F(x)$ a distribution such that $F(0) = 0$ and $F(x) < 1$ for some $x >0 $, then $F(x)$ is an exponential distribution iff

$$
F(x+y) - F(y) = F(x)[1-F(y)], \forall x,y \ge 0
$$
\end{theorem}

\textbf{Proof}. ($\Rightarrow$) 




\subsection{Birth and Death Processes}

To generalize the pure birth processes, we can permit $X(t)$ to decrease as well as increase, for example, by the death of members. This can be regarded as the continuous time analogs of random walks. 


\begin{itemize}
	\item $P_{i, i+1}(h) = \lambda_i h + o(h), h \to 0_+$, $i \ge 0$
	\item $P_{i, i-1}(h) = \mu_i h + o(h), h \to 0_+$, $i \ge 1$
	\item $P_{i,I} (h) = 1 -(\lambda_i + \mu_i) h + o(h), h \to 0_+$, $i \ge 0$
	\item $P_{ij} (0) = \delta_{ij}$
	\item $\mu_0 = 0$, $\lambda_0 > 0, \mu_i, \lambda_i > 0, i=1,2,\cdots$
\end{itemize}

The matrix $A$, the \textbf{infinitesimal generator} of the process,

$$
A = \begin{bmatrix}
-\lambda_0 & \lambda_0 & 0 & 0 & \cdots \\
\mu_1 & -(\lambda_1 + \mu_1)  & \lambda_1 & 0 & \cdots \\
0 & \mu_2 & -(\lambda_2 + \mu_2) & \lambda_2 & \cdots \\
0 & 0 & \mu_3 & -(\lambda_3 + \mu_3) & \cdots
\vdots & \vdots &  \vdots &  \vdots &   & 
\end{bmatrix}
$$


\section{Problems}

(4.2.) Assume a device fails when a cumulative effect of $k$ shocks occur. If the shocks happen 

$$
f(t) = \begin{cases}
\frac{\lambda^k t^{k-1} e^{-\lambda t}}{\Gamma(k)} & t>0 \\[8pt]
0 & t \le 0
\end{cases}
$$


(4.6.) Let $X(t)$ be a homogeneous Poisson process with parameter $\lambda$. Determine the covariance between $X(t)$ and $X(t + \tau)$ where $t > 0$ and $\tau > 0$, i.e. compute

$$
\mathbb{E} \left[ \left( X(t) - \mathbb{E}(X(t)) \right) \left( X(t+\tau) - \mathbb{E}(X(t+\tau)) \right) \right]
$$



(4.9.) Let $X(t)$ be a pure birth continuous time Markov chain. Assume that 

$$
\begin{aligned}
P(event \in (t, th) | X(t) = odd) &= \lambda_1 h + o(h) \\[8pt]
P(event \in (t, th) | X(t) = odd) &= \lambda_1 h + o(h) \\[8pt]
\end{aligned}
$$


For the single-server process with $\lambda < \mu$ the stationary distribution is 

$$
\pi_n = \frac{\lambda_0 \lambda_1 \cdots \lambda_{n-1} }{\mu_1 \mu_2 \cdots \mu_n} = (\frac{\lambda}{\mu})^n
$$

which, when normalized, results in

$$
P_n = \frac{\mu - \lambda}{\mu} (\frac{\lambda}{\mu})^n, \ \ n \ge 0
$$


If the process has been going on a long time and $\lambda < \mu$, the probability of being served immediately upon arrival is 

$$
P_0 = (1 - \frac{\lambda}{\mu})
$$


If an arriving customer finds $n$ people in front of her, her total waiting time $T$, including his own service time, is the sum of service times of herself and those ahead, all distributed exponentially with param $\mu$, thus 

$$
\begin{aligned}
T | n \ \ \mathrm{ahead} &\equiv Gamma(n+1, \mu) \\[8pt]
\Leftrightarrow \ \ P \{ T \le t | n \ \ \mathrm{ahead}  \} &= \int_0^t \frac{\mu^{n+1} \tau^n e^{-\mu t} }{\Gamma(n+1)} d\tau \\[10pt]
\therefore \ \ P \{ T \le t\} &= \sum_{n=0}^\infty P \{ T \le t | n \ \ \mathrm{ahead} \} \cdot (\frac{\lambda}{\mu})^n (1 - \frac{\lambda}{\mu})
\end{aligned}
$$  

since $(\frac{\lambda}{\mu})^n (1 - \frac{\lambda}{\mu})$ is the probability that in the stationary case a customer on arrival will find $n$ ahead in line. 


$$
\begin{aligned}
P \{ T \le t\} &= \\[8pt]
\end{aligned}
$$



$$
\begin{aligned}
M(t) &= \sum_{j=0}^\infty j P_{ij}(t) \\[8pt]
M'(t) &= \lambda - \mu M(t) \\[8pt]
M(t) &= \frac{\lambda}{\mu} (1 - e^{-\mu t}) + i e^{-\mu t} \\[8pt]
\end{aligned}
$$

If we let $t \to \infty$, then $M(t) \to \lambda/\mu$, which is the mean value of the stationary distribution given above. 





\end{document}