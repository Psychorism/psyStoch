\documentclass[12pt]{article} 

\usepackage{geometry}
\geometry{a4paper} 

\usepackage{graphicx} 
\usepackage{enumitem}
\usepackage{booktabs}

\usepackage{float} 
\usepackage{wrapfig} 

\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{dsfont}

\usepackage{xcolor}
\usepackage{listings}
\usepackage{caption}
\DeclareCaptionFont{white}{\color{white}}
\DeclareCaptionFormat{listing}{%
  \parbox{\textwidth}{\colorbox{gray}{\parbox{\textwidth}{#1#2#3}}\vskip-2pt}}
\captionsetup[lstlisting]{format=listing,labelfont=white,textfont=white}
\lstset{frame=lrb,xleftmargin=\fboxsep,xrightmargin=-\fboxsep}

\linespread{1.2} 
\setlength{\parskip}{\baselineskip} % vertical spaces
\setlength\parindent{0pt} % remove all indentation from paragraphs


\usepackage{ntheorem}
\usepackage{mdframed}

\theoremstyle{nonumberbreak}
\theoremheaderfont{\bfseries}
\newmdtheoremenv[%
linecolor=gray,leftmargin=10,%
rightmargin=10,
backgroundcolor=gray!20,%
innertopmargin=0pt,%
ntheorem]{theorem}{}




\begin{document}

\title{\textbf{Markov Chains}}
\author{Hyunwoo Gu}
\date{}

\maketitle


%----------------------------------------------------------------------------------------
%   Section 1
%----------------------------------------------------------------------------------------
\section{Markov Chains}

A discrete time Markov chain $\{ X_n \}$ is a Markov stochastic process whose state space is a countable or finite set. 

\bigskip

\begin{theorem}
\textbf{Definition}. The \textbf{Markov chain} $\{X_n\}$ is a stochastic process such that

$$
P(X_n = j | X_{n-1} = i_{n-1}, \cdots, X_0 = i_0) = P(X_n = j | X_{n-1} = i_{n-1})
$$

for any $i_0, \cdots, i_{n-1}, j \in \mathcal{S}$, the state space. 
\end{theorem}


We have

$$
\begin{aligned}
P\left[ X_0 = i_0, \cdots, X_n = i_n \right] &= P[X_n = i_n | X_0 = i_0, \cdots, X_{n-1} = i_{n-1}] \\[8pt]
&\cdot P(X_0 = i_0, \cdots, X_{n-1} = i_{n-1}) \\[8pt]
&= P(X_n = i_n | X_{n-1} = i_{n-1}) \cdots P(X_1 = i_1 | X_0 = i_0) P(X_0 = i_0)
\end{aligned}
$$


\pagebreak
\textbf{Chapman-Kolmogorov Equation}


\begin{theorem}
\textbf{Definition}. A stochastic process $\{X_t \}_a^b$ is said to satisfy the Markov property if for any $a \le t_1 < \cdots < t_n < t \le b$, the equality 

$$
P(X_t \le x | X_{t_1}, \cdots, X_{t_n} ) = P(X_t \le x | X_{t_n})
$$

holds for any $x \in \mathbb{R}$, or equivalently, the equality

$$
P(X_t \le x | X_{t_i} = y_i, i=1,\cdots,n ) = P(X_t \le x | X_{t_n} = y_n)
$$

holds for any $y_i \in \mathbb{R}$. 

\textbf{Lemma}. Suppose a stochastic process $X_t$, $a \le t \le b$ is adapted to a filtration $\{\mathcal{F}_t : a \le t \le b \}$ and satisfies the condition

$$
P (X_t \le x | \mathcal{F}_s) = P(X_t \le x | X_s), \forall s < t, x\in \mathbb{R}
$$

then $X_t$ is a Markov process
\end{theorem}


\textbf{Proof}. Let $t_1 < t_2 < \cdots < t_n < t$ and $x \in \mathbb{R}$. Then 

$$
\begin{aligned}
P(X_t \le x | X_{t_1}, \cdots, X_{t_n} ) &= \mathbb{E} \left[ P(X_t \le x | \mathcal{F}_{t_n}) | X_{t_1}, \cdots, X_{t_n} \right] \\[8pt]
&= \mathbb{E} \left[ P(X_t \le x | X_{t_n}) | X_{t_1}, \cdots, X_{t_n} \right]
&= P(X_t \le x | X_{t_n})
\end{aligned}
$$

Define the conditional probability $P_{s,x}(t, dy) := P(X_t \in dy | X_s = x)$ a \textbf{transition probability} of a Markov process $X_t$. 


\begin{theorem}
\textbf{Definition}. The equality is called \textbf{Chapman-Kolmogorov equation}:

$$
P_{s,x} (t,A) = \int_{-\infty}^\infty P_{u,z}(t,A) P_{s,x}(u,dz)
$$

for all $s < u < t$, $x \in \mathbb{R}$, and $A \in \mathcal{B}(\mathbb{R})$, the Borel field of $\mathbb{R}$. 

This is due to 

$$
\begin{aligned}
P(X_{t_1} \le c_1, \cdots, X_{t_n} \le c_n) &= \int_{-\infty}^{c_1} \cdots \int_{-\infty}^{c_n} P_{t_{n-1}, x_{n-1}} (t_n, dx_n) \\[8pt]
&\times \cdots P_{t_1, x_1} (t_2, dx_2) \nu(dx_1)
\end{aligned}
$$

\end{theorem}


\subsection{Examples of Markov chains}


\subsubsection*{Spatially homogeneous Markov chains}

Let $\xi_1, \xi_2, \cdots$ IID samples such that $P(\xi = i) = a_i$. Let $\eta_n := \sum_{i=1}^n \xi_i$

$$
P = \begin{bmatrix}
a_0 & a_1 & a_2 & a_3 & \cdots \\
0 & a_0 & a_1 & a_2 & \cdots \\
0 & 0 & a_0 & a_1 &  \cdots \\
\vdots & & & & \\
\end{bmatrix}
$$

Note that

$$
P(X_{n+1} = j | X_n \ i) = \begin{cases} a_{j-i} & j \ge i \\ 0 & j < i \end{cases}
$$


\subsubsection*{One-dimensional random walks}

$$
P = \begin{bmatrix}
r_0 & p_0 & 0 & 0 & \cdots \\
q_1 & r_1 & p_1 & 0 & \cdots \\
0 & q_2 & r_2 & p_2 & \cdots \\
\vdots & & & & \\
\end{bmatrix}
$$

Note that $P(X_{n+1} = i+1 | X_n = i) = p_i$, $P(X_{n+1} = i-1 | X_n = i) = q_i$, $P(X_{n+1} = i | X_n = i) = r_i$


\subsubsection*{Gambler's ruin}

Let 

\begin{itemize}
	\item $N - i$ : Casino's initial wealth
	\item $i$ : Gambler's initial wealth
\end{itemize}

For $S := \{ 0,1,\cdots, N \}$

$$
\begin{aligned}
P_{i,i+1} &= p, P_{i,i-1} = 1-p \\[8pt]
P_{0,0} &= 1, P_{N,N} = 1
\end{aligned}
$$

We have the state spaces 

$$S = \{ 0\} \cup \{ 1, \cdots, N-1\} \cup \{ N\}$$

\subsubsection*{Two-dimensional random walks}

\subsubsection*{Three-dimensional random walks}

\subsubsection*{Success runs}

\subsubsection*{Branching processes}



\subsection{Classifications of states of a Markov chains}


\subsubsection*{Accessibility}

State $j$ is \textbf{accessible} from state $i$ if $\exists n \ge 0$ such that $P^n_{ij} > 0$. Two states $i$ and $j$, each accessible to the other, are saide to \textbf{communicate}. If $i$ and $j$ do not communicate, then either

$$
P^n_{ij} = 0, \forall n \ge 0 \ \ or \ \ P^n_{ji} = 0, \forall n \ge 0 
$$

The properties of \textbf{communicaiton} as an \textbf{equivalence relation}:

\begin{itemize}
	\item (\textbf{Reflexivity}) : a consequence from the definition of $P^0_{ij} = \delta_{ij}$
	\item (\textbf{Symmetry}) : a consequence from the definition
	\item (\textbf{Transitivity})
\end{itemize}

(\textbf{Proof of transitivity}). $i \leftrightarrow j$ and $j \leftrightarrow k$ imply that there exist $n,m \in \mathbb{N}$ such that $P_{ij}^n >0$ and $P_{jk}^m >0$. Thus 

$$
P_{ij}^{n+m} = \sum_{r=0}^\infty P_{ir}^n P_{rk}^m \ge P_{ij}^n P_{jk}^m > 0
$$

And the similar argument shows the opposite way. 

We can say all the states are equivalent if there is no inner loop comming back to the state with probability 1. 


\subsubsection*{Periodicity}

\textbf{Period} of state $i$, $d(i)$ is the greatest common divisor(GCD) of all integers $n \ge 1$ where $P^n_{ii} > 0$, i.e.

$$
d(i) \equiv GCD \{ n : P_{ii}^n > 0 \}
$$

If $d(i) = 1$, then the state $i$ is called \textbf{aperiodic}. 

$$
P = \begin{bmatrix}
0 & 1 & 0 & 0 & \cdots & 0 \\
0 & 0 & 1 & 0 & \cdots & 0 \\
\vdots &  &  &  &  & \vdots \\
0 & 0 & 0 & 0 & \cdots & 1 \\
1 & 0 & 0 & 0 & \cdots & 0 \\
\end{bmatrix}
$$



\begin{theorem}
\textbf{Theorem 4.1}. Periodicity is a \textbf{class property}, i.e, if $i \leftrightarrow j$ then

$$
d(i) = d(j)
$$

\textbf{Theorem 4.2.}. If state $i$ has period $d(i)$ then there exists an integer $N$ depending on $i$ such that $\forall n \ge N$,

$$
P_{ii}^{nd(i)} > 0
$$

which asserts that a return to state i can occur at all sufficiently large multiples of the period $d(i)$. 
\end{theorem}



\subsubsection*{Recurrence}

Let us define

$$
f_{ii}^n := P(X_n = i, X_{n-1} \neq i, \cdots, X_1 \neq 1 | X_0 = i)
$$

Note that 

$$
P_{ii}^n := \sum_{k=0}^n f_{ii}^k P_{ii}^{n-k}
$$

where $f_{ii}^0 := 0$. 


\begin{theorem}
\textbf{Definition}. The \textbf{generating function} $P_{ij}(s)$ of the sequence $\{ P_{ij}^n \}$ is 

$$
P_{ij} (s) = \sum_{n=0}^\infty P_{ij}^n s^n, \forall |s|<1
$$

In a similar manner, the generating function of the sequence $\{ f_{ij}^n \}$ is 

$$
F_{ij}(s) = \sum_{n=0}^\infty f_{ij}^n s^n, \forall |s|
$$
\end{theorem}


We say a state $i$ is \textbf{recurrent} if and only if $\sum_{n=1}^\infty f_{ii}^n = 1$. i.e. it has \textbf{finite first return time}, a.s., where the first return time can be defined 

$$
\tau_{ii} := \begin{cases} min(n \ge 1 : X_n = i | X_0 =i) \\ \infty & P( X_n = i | X_0 =i) = 0 \end{cases}
$$

where $\sum_{n=1}^\infty f_{ii}^n = Pr(\tau_{ii} < \infty)$. 



\begin{theorem}
\textbf{Theorem 5.1.}. A state $i$ is recurrent if and only if 

$$
\sum_{n=1}^\infty P_{ii}^n = \infty
$$
\end{theorem}


\textbf{Proof} Assume $i$ is recurrent, that is, $\sum_{n=1}^\infty f_{ii}^n = 1$. Then by Lemma 5.1,

$$
\mathrm{lim}_{s \to 1-} \sum_{n=0}^\infty f_{ii}^n s^n = \mathrm{lim}_{s \to 1-} F_{ii}(s) = 1
$$

Thus using the fact that 

$$
\mathrm{lim}_{s \to 1-} P_{ii}(s) = \mathrm{lim}_{s \to 1-} \sum_{n=0}^\infty P_{ii}^n s^n = \infty
$$


\begin{theorem}
\textbf{Corollary 5.1.}. If $i \leftrightarrow j$ and if $i$ is recurrent then $j$ is recurrent.
\end{theorem}

i.e. \textbf{recurrence is the class property}.



\begin{theorem}
\textbf{Fact 1}. In irreducible MCs, all states are either \textbf{recurrent} or \textbf{transient}. 

\textbf{Fact 2}. In \textbf{finite}, irreducible MCs, all states are either \textbf{recurrent}. 
\end{theorem}

For example, 

\begin{itemize}
	\item An asymmetric 1D random walk is \textbf{transient}, since there is a probability of absorption 
	\item A symmetric 1D random walk is \textbf{aperiodic}, since it has period 2.
	\item In \textbf{gambler's ruin}, the states are \textbf{irreducible}
\end{itemize}



\subsection{Ergodic theorem}

\begin{theorem}
\textbf{Ergodic theorem}. Let $X_t$ irreducible, ergodic(recurrent and aperiodic) Markov chain. Then

$$
\begin{aligned}
\exists \mathrm{lim}_{n\to\infty} P_{ij}(n) =& \pi_j^\ast > 0 \\[8pt]
\sum_{j=1}^M \pi_j^\ast &= 1
\end{aligned}
$$
\end{theorem}



\begin{theorem}
\textbf{Corollary1}. $\pi P = \pi$

\textbf{Corollary2}. $\mathrm{lim}_{n\to\infty} P(X_n = j) = \pi_j$

\end{theorem}

where \textbf{corollary2} is equivalent to 

$$
\mathrm{lim}_{n\to\infty} \frac{1}{n}\sum_{i=1}^n I(X_k=j | X_0=j) = \pi_j
$$


We have the following additional theorem:


\begin{theorem}
\textbf{Theorem 1.1.}. Let $\{a_k \}$, $\{u_k \}$, $\{b_k \}$ be sequences indexed by $k=0, \pm 1, \pm 2, \cdots$ that the GCD of the integer $k$ for which $a_k >0$ is 1. If the renewal equation, for $n = 0, \pm 1, \pm 2, \cdots$

$$
u_n - \sum_{k=-\infty}^\infty a_{n-k} u_k = b_n
$$

is satisfied by a bounded sequence $\{ u_n\}$ of real numbers, then 

$$
\exists \mathrm{lim}_{n\to \infty} u_n, \exists \mathrm{lim}_{n\to -\infty} u_n
$$. Furthermore, if

$$
\mathrm{lim}_{n\to - \infty} u_n = 0
$$

then 

$$
\mathrm{lim}_{n\to \infty} u_n
$$

\end{theorem}





\subsection*{Quizzes}

\textbf{(Quiz 1)}. Find the stationary distribution of the following $P$:

$$
P = \begin{bmatrix}
0 & 1/2 & 0 & 0 & 1/2 \\
0 & 0 & 1 & 0 & 0 \\
1/5 & 1/5 & 1/5 & 1/5 & 1/5 \\
0 & 1/2 & 0 & 0 & 1/2 \\
0 & 1/2 & 1/2 & 0 & 0 \\
\end{bmatrix}
$$

\textbf{(Answer)} The left-eigenvector corresponding to eigenvalue $1$ is as follows:

$$
(1/12, 3/12, 5/12, 1/12, 2)
$$



\textbf{(Quiz 2)}. Jane and Peter are playing chess. For Jane, the probabilities of wining, drawing, and losing a game number $t$ are $(w,d,l)$. Peter is slightly more emotional.

\begin{itemize}
	\item If he wins in the previous game, then $(w+\epsilon, d, l-\epsilon)$
	\item If he draws in the previous game, then $(w, d, l)$
	\item If he loses in the previous game, then $(w-\epsilon, d, l+\epsilon)$
\end{itemize}

Find the condition which guarantees that the probability of wining in stationry distribution for Peter is larger than that for Jane.


\textbf{(Answer)} Note that 

$$
\begin{aligned}
P_{Jane} &= \begin{bmatrix}
w & d & l \\
w & d & l \\
w & d & l \\
\end{bmatrix}
P_{Peter} &= \begin{bmatrix}
w + \epsilon& d & l-\epsilon \\
w & d & l \\
w - \epsilon & d & l+\epsilon \\
\end{bmatrix}
\end{aligned}
$$

It is direct that $Rank(P_{Jane}^T) = 1$, thus the multiplicity of $\lambda = 0$ is at least $2$. Note that $\lambda =1$ is also an eigenvalue, where the corresponding eigenvector is $(w,d,l)$. 

For $P_{Peter}^T$, we need some algebra to get

$$
x_1 = \frac{w(1-\epsilon) - l\epsilon}{1-2\epsilon}
$$

then by $w < x_1$, we have

$$
l < w
$$



\textbf{(Quiz 3)}. 

Is the following $P$ \textbf{ergodic}?

$$
P = \begin{bmatrix}
0 & 1/2 & 0 & 1/2 & 0 & 0 \\
0 & 0 & 1 & 0 & 0 & 0 \\
0 & 0 & 0 & 1/2 & 0 & 1/2 \\
0 & 0 & 0 & 0 & 1 & 0 \\
0 & 0 & 0 & 0 & 0 & 1 \\
1 & 0 & 0 & 0 & 0 & 0 \\
\end{bmatrix}
$$


\textbf{(Answer)} Note that it is \textbf{irreducible} and \textbf{recurrent}, but not \textbf{aperiodic}.


\textbf{(Quiz 4)}. 

Tell the number of equivalence classes, and all the periodic states of the following transition matrix:

$$
P = \begin{bmatrix}
1/3 & 1/3 & 1/3 & 0 \\
1/2 & 1/2 & 0 & 0 \\
1/4 & 1/4 & 0 & 1/2 \\
0 & 1/2 & 0 & 1/2 \\
\end{bmatrix}
$$

\textbf{(Answer)} Note that it is \textbf{irreducible} and \textbf{recurrent}. Note that $P_{11} > 0$, thus all the states are aperiodic. 


\textbf{(Quiz 5)}. 

Assume that there is a series of integer numbers, in which numbers $0,1,\cdots, 9$ appear randomly and independently of each other with equal probabilities. Let $x_n$ be a quantity of different numbers in $n$ first elements of the series. Find a stationary distribution of this chain.

\textbf{(Answer)}

$$
P = \begin{bmatrix}
1/9 & 8/9 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
0 & 2/9 & 7/9 & 0 & 0 & 0 & 0 & 0 & 0 \\
0 & 0 & 3/9 & 6/9 & 0 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 4/9 & 5/9 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 5/9 & 4/9 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 & 6/9 & 3/9 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 & 0 & 7/9 & 2/9 & 0 \\
0 & 0 & 0 & 0 & 0 & 0 & 0 & 8/9 & 1/9 \\
0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 \\
\end{bmatrix}
$$

Clearly the left eigenvector corresponding to $\lambda:=1$ is $(0, \cdots, 1)$. 



\end{document}